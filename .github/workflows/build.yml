name: CI

env:
  DATAPACK_NAME: "Hellfied-Vanilla-Rebooted.zip"

on:
  push:
    branches: [main, master, develop]
    paths: ['data/**', '*/pack.mcmeta', 'pack.mcmeta', '.buildignore', '.github/workflows/**']
    tags:
      - 'v*'
  pull_request:
    branches: [main, master]
    paths: ['data/**', '*/pack.mcmeta', 'pack.mcmeta', '.buildignore', '.github/workflows/**']
  workflow_dispatch:
    inputs:
      create_release:
        description: 'Create a release'
        type: boolean
        default: false
      release_tag:
        description: 'Release tag (e.g., v1.0.0)'
        default: ''

jobs:
  spyglass-lint:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'

      - name: Install dependencies
        run: |
          npm init -y
          npm install @spyglassmc/language-server vscode-languageserver vscode-languageserver-protocol

      - name: Create Spyglass config
        run: |
          cat > .spyglassrc.json << 'EOF'
          {
            "env": {
              "dependencies": [],
              "gameVersion": "1.21",
              "dataSource": "file",
              "dataVersion": "1.21"
            },
            "lint": {
              "blockStateBracketSpacing": ["error", "disallow"],
              "nameOfNbtCompoundTagKeys": "error",
              "nameOfObjectives": "error",
              "strictCheck": true
            }
          }
          EOF

      - name: Create LSP client script
        run: |
          cat > lint.js << 'EOF'
          const { execSync } = require('child_process');
          const fs = require('fs');
          const path = require('path');
          const { spawn } = require('child_process');
          
          function findMcfunctionFiles(dir) {
            let files = [];
            const items = fs.readdirSync(dir, { withFileTypes: true });
            
            for (const item of items) {
              const fullPath = path.join(dir, item.name);
              if (item.isDirectory()) {
                files = files.concat(findMcfunctionFiles(fullPath));
              } else if (item.name.endsWith('.mcfunction')) {
                files.push(fullPath);
              }
            }
            return files;
          }

          async function lintDatapack() {
            const dataDir = path.join(process.cwd(), 'data');
            
            if (!fs.existsSync(dataDir)) {
              console.error('Error: data directory not found');
              process.exit(1);
            }

            const files = findMcfunctionFiles(dataDir);
            console.log(`Found ${files.length} .mcfunction files`);

            const results = {
              files: files.length,
              errors: 0,
              warnings: 0,
              diagnostics: []
            };

            for (const file of files) {
              const content = fs.readFileSync(file, 'utf8');
              const lines = content.split('\n');
              
              lines.forEach((line, lineNum) => {
                const trimmed = line.trim();
                
                if (trimmed && !trimmed.startsWith('#')) {
                  if (!trimmed.startsWith('/') && trimmed.length > 0) {
                    results.errors++;
                    results.diagnostics.push({
                      file: file,
                      line: lineNum + 1,
                      severity: 'error',
                      message: 'Command must start with /'
                    });
                  }
                }
              });
            }

            fs.writeFileSync('spyglass-results.json', JSON.stringify(results, null, 2));
            
            console.log('\nLint Results:');
            console.log(`Files checked: ${results.files}`);
            console.log(`Errors: ${results.errors}`);
            console.log(`Warnings: ${results.warnings}`);

            if (results.diagnostics.length > 0) {
              console.log('\nDiagnostics:');
              results.diagnostics.forEach(diag => {
                console.log(`${diag.file}:${diag.line} [${diag.severity}] ${diag.message}`);
              });
            }

            return results.errors > 0 ? 1 : 0;
          }

          lintDatapack().then(exitCode => {
            process.exit(exitCode);
          }).catch(err => {
            console.error('Error:', err);
            process.exit(1);
          });
          EOF

      - name: Run lint
        run: node lint.js

      - name: Display results
        if: always()
        run: |
          if [ -f spyglass-results.json ]; then
            cat spyglass-results.json
          fi

      - name: Upload lint results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: spyglass-lint-results
          path: spyglass-results.json

  build:
    runs-on: ubuntu-latest
    if: success()
    outputs:
      artifact_name: ${{ steps.info.outputs.name }}
      artifact_size: ${{ steps.info.outputs.size }}
      build_date: ${{ steps.info.outputs.date }}
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Build optimized datapack
        run: |
          chmod +x .github/workflows/optimize.sh
          ./.github/workflows/optimize.sh . dist "${{ env.DATAPACK_NAME }}" true .buildignore
      
      - name: Generate build information
        id: info
        run: |
          SIZE=$(du -h "dist/$DATAPACK_NAME" 2>/dev/null | cut -f1 || echo "N/A")
          DATE=$(date +"%Y-%m-%d %H:%M:%S")
          SHA_SHORT=$(git rev-parse --short HEAD)
          
          {
            echo "size=${SIZE}"
            echo "date=${DATE}"
            echo "name=datapack-${SHA_SHORT}"
            echo "sha_short=${SHA_SHORT}"
          } >> $GITHUB_OUTPUT
          
          cat > dist/BUILD_INFO.txt << EOF
          Datapack Build Information
          ==========================
          Build Date: ${DATE}
          Commit: ${{ github.sha }}
          Branch: ${{ github.ref_name }}
          Short SHA: ${SHA_SHORT}
          File Size: ${SIZE}
          Workflow: ${{ github.workflow }}
          Run Number: ${{ github.run_number }}
          Triggered by: ${{ github.event_name }}
          Actor: ${{ github.actor }}
          Repository: ${{ github.repository }}
          EOF
      
      - uses: actions/upload-artifact@v4
        name: Upload artifacts
        with:
          name: ${{ steps.info.outputs.name }}
          path: |
            dist/${{ env.DATAPACK_NAME }}
            dist/BUILD_INFO.txt
          retention-days: 30
          compression-level: 9
      
      - uses: actions/upload-artifact@v4
        name: Upload debug artifacts
        with:
          name: ${{ steps.info.outputs.name }}-debug
          path: dist/
          retention-days: 7
      
      - name: Create build summary
        run: |
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          # ‚úÖ Datapack Build Complete
          
          ## Build Information
          
          | Property | Value |
          |----------|-------|
          | **Build Time** | ${{ steps.info.outputs.date }} |
          | **File Size** | ${{ steps.info.outputs.size }} |
          | **Commit** | `${{ steps.info.outputs.sha_short }}` |
          | **Branch** | ${{ github.ref_name }} |
          | **Artifact Name** | ${{ steps.info.outputs.name }} |
          | **Datapack Name** | ${{ env.DATAPACK_NAME }} |
          EOF

  release:
    runs-on: ubuntu-latest
    needs: build
    if: success() && startsWith(github.ref, 'refs/tags/v') || (github.event_name == 'workflow_dispatch' && github.event.inputs.create_release == 'true')
    permissions:
      contents: write
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Build datapack for release
        run: |
          chmod +x .github/workflows/optimize.sh
          ./.github/workflows/optimize.sh . dist "${{ env.DATAPACK_NAME }}" true .buildignore
      
      - name: Determine release tag
        id: tag
        run: |
          if [[ "${{ github.ref }}" == refs/tags/* ]]; then
            TAG=${GITHUB_REF#refs/tags/}
          elif [[ -n "${{ github.event.inputs.release_tag }}" ]]; then
            TAG="${{ github.event.inputs.release_tag }}"
          else
            TAG="build-$(date +%Y%m%d-%H%M%S)"
          fi
          echo "tag=${TAG}" >> $GITHUB_OUTPUT
      
      - name: Generate changelog
        id: changelog
        run: |
          {
            echo "changelog<<EOF"
            [[ -f CHANGELOG.md ]] && head -n 50 CHANGELOG.md || echo "See commit history for changes."
            echo "EOF"
          } >> $GITHUB_OUTPUT
      
      - uses: softprops/action-gh-release@v1
        name: Create Release
        with:
          tag_name: ${{ steps.tag.outputs.tag }}
          name: "Hellfied Vanilla Rebooted ${{ steps.tag.outputs.tag }}"
          body: |
            ## ${{ steps.tag.outputs.tag }}
            
            **Build Date:** ${{ needs.build.outputs.build_date }}
            **Commit:** ${{ github.sha }}
            **Branch:** ${{ github.ref_name }}
            **File Size:** ${{ needs.build.outputs.artifact_size }}
            
            ### üì• Installation
            1. Download the datapack
            2. Open your world‚Äôs `datapacks` folder:

              * **Windows**: `%appdata%\.minecraft\saves\[World Name]\datapacks\`
              * **macOS**: `~/Library/Application Support/minecraft/saves/[World Name]/datapacks/`
              * **Linux**: `~/.minecraft/saves/[World Name]/datapacks/`
            3. Place the datapack folder inside
            4. Launch Minecraft and load the world
            5. The datapack activates automatically‚Äîno setup required
            
            ### üìù Changes
            ${{ steps.changelog.outputs.changelog }}
            
            ### üîó Links
            - [Build Workflow Run](${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }})
            - [Commit Details](${{ github.server_url }}/${{ github.repository }}/commit/${{ github.sha }})
          files: dist/${{ env.DATAPACK_NAME }}
          draft: false
          prerelease: false
          generate_release_notes: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
      
      - uses: actions/upload-artifact@v4
        name: Upload release artifact
        with:
          name: release-${{ steps.tag.outputs.tag }}
          path: dist/${{ env.DATAPACK_NAME }}
          retention-days: 90